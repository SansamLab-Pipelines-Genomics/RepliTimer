configfile: "config/config.yml"

##################################################################
##                   import samples .csv file                   ##
##################################################################

# this imports the pandas package functionality in an object named pd
import pandas as pd

# this reads the CSV file and sets an index using the values in the "sample" column.
samples_table = pd.read_csv(config["samples_table"]).set_index("sample", drop=False)

# fastq filename input function definition set to Python dictionary
def fq_dict_from_sample(wildcards):
  return {
    "fq1": samples_table.loc[wildcards.sample, "fastq1"],
    "fq2": samples_table.loc[wildcards.sample, "fastq2"]
  }

#################################################################
##                     Define target files                     ##
#################################################################

# to run snakemake without explicitly requesting any output files on the command line, we must request output files in the first rule. Therefore we include this otherwise useless rule here  
rule all:
    input:
        expand("results/bedgraphs/{sample}_ZScores_bedgraphs.gz",sample = config["experiment_name"]),
        expand("results/bedgraphs/{sample}_Smoothed_bedgraphs.gz",sample = config["experiment_name"]),
        expand("results/bedgraphs/{sample}_Quotients_bedgraphs.gz",sample = config["experiment_name"]),
        expand("results/bedgraphs/{sample}_Log2Ratios_bedgraphs.gz",sample = config["experiment_name"])

##################################################################
##                          Trim reads                          ##
##################################################################

rule trim_reads_with_fastp:
    input:
        unpack(fq_dict_from_sample)   # <--- we need to wrap our input function inside a special Snakemake function called unpack() which turns the dict into a collection of named inputs
    params:
        threads=config["fastp_cpus"]
    output:
        trimmed1="results/trimmed/{sample}_trimmed_R1.fastq.gz",
        trimmed2="results/trimmed/{sample}_trimmed_R2.fastq.gz",
        fastp_report="results/qc/fastp_reports/{sample}.html",
        fastp_json="results/qc/fastp_reports/{sample}.json"
    envmodules:
        config["fastp"]
    conda:
        "envs/trim_reads_with_fastp.yml"
    log: "results/logs/snakelogs/trim_reads_with_fastp.{sample}.log"
    shell:
        """
        fastp -i {input.fq1} -I {input.fq2} -o {output.trimmed1} -O {output.trimmed2} -h {output.fastp_report} --json {output.fastp_json} -R "{wildcards.sample}" -w {params.threads}
        """

#################################################################
##                    Align reads to genome                    ##
#################################################################

rule align_reads_with_bwamem:
    input:
        R1="results/trimmed/{sample}_trimmed_R1.fastq.gz",
        R2="results/trimmed/{sample}_trimmed_R2.fastq.gz"
    params:
        genome=config["bwa_genome"],
        threads=config["bwa_cpus"]
    output:
        bam="results/aligned/{sample}.bam",
        bai="results/aligned/{sample}.bam.bai"
    envmodules:
        config["bwa"],
        config["samtools"]
    conda:
        "envs/align_reads_with_bwamem.yml"
    log: "results/logs/snakelogs/align_reads_with_bwamem.{sample}.log"
    shell:
        """
        bwa mem -M -t {params.threads} {params.genome} {input.R1} {input.R2} | samtools sort -@ {params.threads} > {output.bam}
        samtools index -@ {params.threads} {output.bam} > {output.bai}
        """

##################################################################
##                     Mark duplicate reads                     ##
##################################################################

rule mark_duplicates_with_picard:
    input:
        bam="results/aligned/{sample}.bam"
    params:
        memory=config["picard_memory"]
    output:
        marked_bam="results/duplicatesMarkedBam/{sample}.bam",
        marked_bai="results/duplicatesMarkedBam/{sample}.bam.bai",
        marked_metrics="results/logs/picard_metrics/{sample}.marked.duplicates_metrics.txt"
    envmodules:
        config["samtools"],
        config["picard"]
    conda:
        "envs/mark_duplicates_with_picard.yml"
    log: "results/logs/snakelogs/mark_duplicates_with_picard.{sample}.log"
    shell:
        """
        JAVA_MEM_OPTS={params.memory}
        RAM=$(echo $JAVA_MEM_OPTS | rev | cut -c2- | rev)
        picard MarkDuplicates COMPRESSION_LEVEL=9 VALIDATION_STRINGENCY=LENIENT MAX_RECORDS_IN_RAM=$((200000*RAM)) CREATE_INDEX=true I={input.bam} O={output.marked_bam} M={output.marked_metrics}
        samtools index {output.marked_bam}
        """

##################################################################
##              Filter .bam files based on quality              ##
##################################################################

rule quality_filter_with_bamtools:
    input:
        marked_bam="results/duplicatesMarkedBam/{sample}.bam"
    params:
        mapQ=config["bamtools_filter_mapQ"]
    output:
        filtered_bam="results/filteredBams/{sample}.bam"
        #filtered_bai="results/filteredBams/{sample}.bam.bai"
    envmodules:
        config["samtools"],
        config["bamtools"]
    conda:
        "envs/quality_filter_with_bamtools.yml"
    log: "results/logs/snakelogs/quality_filter_with_bamtools.{sample}.log"
    shell:
        """
        bamtools filter -in {input.marked_bam} -forceCompression -mapQuality '{params.mapQ}' -isDuplicate false -isFailedQC false -isMapped true -isMateMapped true -isPaired true -isPrimaryAlignment true -isProperPair true -out {output.filtered_bam}
        samtools index {output.filtered_bam}
        """

##################################################################
##         Remove reads overlapping blacklisted regions         ##
##################################################################

rule blacklist_filter_with_bedtools:
    input:
        filtered_bam="results/filteredBams/{sample}.bam"
    params:
        HiCount_BED_FILENAME=config["bedtools_intersect_greylist"],
        Sat_BED_FILENAME=config["bedtools_intersect_blacklist"]
    output:   
        doubleFiltered_bam="results/doubleFilteredBams/{sample}.bam"
    envmodules:
        config["samtools"],
        config["bedtools"]
    conda:
        "envs/blacklist_filter_with_bedtools.yml"
    log: "results/logs/snakelogs/blacklist_filter_with_bedtools.{sample}.log"
    shell:
        """
        bedtools intersect -v -split -abam {input.filtered_bam} -b {params.HiCount_BED_FILENAME} > {input.filtered_bam}_FILTERED1.BAM
        bedtools intersect -v -split -f 0.3 -abam {input.filtered_bam}_FILTERED1.BAM -b {params.Sat_BED_FILENAME} > {output.doubleFiltered_bam}
        rm {input.filtered_bam}_FILTERED1.BAM
        samtools index {output.doubleFiltered_bam}
        """

#################################################################
##                  Count reads in RT windows                  ##
#################################################################

rule count_reads_in_RT_windows:
    input:
        doubleFiltered_bam="results/doubleFilteredBams/{sample}.bam"
    params:
        RT_windows=config["RT_windows"]
    output:
        counts="results/counts/{sample}_counts.bedgraph"
    envmodules:
        config["R"],
        config["Bioconductor"]
    conda:
        "envs/R_Scripts.yml"
    log: "results/logs/snakelogs/count_reads_in_RT_windows.{sample}.log"
    shell:
        """
        Rscript workflow/scripts/CountReadsOverBed_ver02.R {params.RT_windows} {input.doubleFiltered_bam} {output.counts}
        """

#################################################################
##                      Merge count tables                     ##
#################################################################

rule merge_count_tables:
        input:
            expand("results/counts/{samples}_counts.bedgraph",samples=samples_table.index)
        output:
            rse_counts="results/rse/{sample}_rse.rds"
        params:
            sample_list=','.join(expand("{samples}",samples=samples_table.index)),
            samples_table=config["samples_table"],
            RT_windows=config["RT_windows"],
            counts_bedgraphs_list=','.join(expand("results/counts/{samples}_counts.bedgraph",samples=samples_table.index))
        envmodules:
            config["R"],
            config["Bioconductor"]
        conda:
            "envs/R_Scripts.yml"
        log: "results/logs/snakelogs/{sample}_merge_count_tables.log"
        script:
            "scripts/MakeCountsRSE_ver02.R"

###################################################################
##                     Process count tables                      ##
###################################################################

rule process_count_tables:
        input:
            rse_counts="results/rse/{sample}_rse.rds"
        output:
            rse_processed="results/processed_rse/{sample}_processed_rse.rds"
        envmodules:
            config["R"],
            config["Bioconductor"]
        conda:
            "envs/R_Scripts.yml"
        log: "results/logs/snakelogs/{sample}_process_count_tables.log"
        shell:
            """
            Rscript workflow/scripts/CalculateQuotientsSmoothScale_ver01.R {input.rse_counts} {output.rse_processed}
            """

#################################################################
##                       Make bedgraphs                        ##
#################################################################

rule make_Log2Ratios_bedgraphs:
        input:
            rse_processed="results/processed_rse/{sample}_processed_rse.rds"
        output:
            Log2Ratios_bedgraphs="results/bedgraphs/{sample}_Log2Ratios_bedgraphs.gz"
        envmodules:
            config["R"],
            config["Bioconductor"]
        conda:
            "envs/R_Scripts.yml"
        log: "results/logs/snakelogs/{sample}_make_Log2Ratios_bedgraphs.log"
        shell:
            """
            mkdir Log2Ratios
            Rscript workflow/scripts/Generate_RT_Bedgraphs_ver01.R {input.rse_processed} "Log2Ratios"
            tar -czvfk {output.Log2Ratios_bedgraphs} Log2Ratios/
            rm -rf Log2Ratios
            """
rule make_ZScores_bedgraphs:
        input:
            rse_processed="results/processed_rse/{sample}_processed_rse.rds"
        output:
            ZScores_bedgraphs="results/bedgraphs/{sample}_ZScores_bedgraphs.gz"
        envmodules:
            config["R"],
            config["Bioconductor"]
        conda:
            "envs/R_Scripts.yml"
        log: "results/logs/snakelogs/{sample}_make_ZScores_bedgraphs.log"
        shell:
            """
            mkdir ZScores
            Rscript workflow/scripts/Generate_RT_Bedgraphs_ver01.R {input.rse_processed} "ZScores"
            tar -czvf {output.ZScores_bedgraphs} ZScores/
            rm -rf ZScores
            """
rule make_Smoothed_bedgraphs:
        input:
            rse_processed="results/processed_rse/{sample}_processed_rse.rds"
        output:
            Smoothed_bedgraphs="results/bedgraphs/{sample}_Smoothed_bedgraphs.gz",
        envmodules:
            config["R"],
            config["Bioconductor"]
        conda:
            "envs/R_Scripts.yml"
        log: "results/logs/snakelogs/{sample}_make_Smoothed_bedgraphs.log"
        shell:
            """
            mkdir Smoothed
            Rscript workflow/scripts/Generate_RT_Bedgraphs_ver01.R {input.rse_processed} "Smoothed"
            tar -czvf {output.Smoothed_bedgraphs} Smoothed/
            rm -rf Smoothed
            """
rule make_Quotients_bedgraphs:
        input:
            rse_processed="results/processed_rse/{sample}_processed_rse.rds"
        output:
            Quotients_bedgraphs="results/bedgraphs/{sample}_Quotients_bedgraphs.gz"
        envmodules:
            config["R"],
            config["Bioconductor"]
        conda:
            "envs/R_Scripts.yml"
        log: "results/logs/snakelogs/{sample}_make_Quotients_bedgraphs.log"
        shell:
            """
            mkdir Quotients
            Rscript workflow/scripts/Generate_RT_Bedgraphs_ver01.R {input.rse_processed} "Quotients"
            tar -czvf {output.Quotients_bedgraphs} Quotients/
            rm -rf Quotients
            """
